{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from pathlib import Path\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.core.pylabtools import figsize\n",
    "from IPython.display import display\n",
    "\n",
    "from src import MODEL_ROOTS\n",
    "from src.tools import TableFormatter\n",
    "from src.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# JUPYTER SETUP\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# NOTE: rcParams are optimized for dark mode, change colours to black if using light mode.\n",
    "%matplotlib inline\n",
    "figsize(15, 10)\n",
    "plt.rcParams.update({'font.size': 18, 'text.color': 'w', 'axes.edgecolor': 'w', 'axes.labelcolor': 'w', 'xtick.color': 'w', 'ytick.color': 'w'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def load_dfs(files: dict[str, Sequence[Path]]):\n",
    "    dfs = [pd.json_normalize(io.load_yaml(f)) for fs in files.values() for f in fs]\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # Add multi-index based on model and item number, since we don't have mean metrics.\n",
    "    models = [f'{k}' for k, fs in files.items() for _ in fs]\n",
    "    df.index = pd.MultiIndex.from_product([models, dfs[0].index], names=['Model', 'Item'])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = MODEL_ROOTS[-1]\n",
    "exp, split = 'benchmark', 'val'\n",
    "ckpt, mode = 'best', '*'  # {best, last}, {stereo, mono, *}\n",
    "res_dir = 'results'\n",
    "fname = f'syns_{split}_{ckpt}_{mode}.yaml'\n",
    "\n",
    "# models = ['garg', 'monodepth2_MS']\n",
    "models = []\n",
    "if not models:\n",
    "    fs = sorted(root.glob(f'{exp}/**/{res_dir}/{fname}'))\n",
    "    models = sorted({f.parents[2].stem for f in fs})\n",
    "\n",
    "print('Evaluation Models:', models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LOAD METRICS\n",
    "# We expect each model to have multiple available checkpoints. e.g. trained with different random seeds.\n",
    "# This is handled by `df.groupby(level=0)`. We report mean performance over all seeds.\n",
    "# StdDev may also be useful to check for outliers that failed to train for some reason.\n",
    "\n",
    "eval_files = {model: sorted(root.glob(f'{exp}/{model}/**/{res_dir}/{fname}')) for model in models}\n",
    "df = load_dfs(eval_files)\n",
    "df_edges = pd.concat([df.pop(k) for k in df.columns if k.endswith('-Edges')], axis=1)\n",
    "\n",
    "df_agg = df.groupby(level=0)  # Group all metrics from different seeds for each model\n",
    "\n",
    "df_mean = df_agg.agg('mean').reindex(models)\n",
    "df_mean.columns.name = 'Mean'\n",
    "\n",
    "df_std = df_agg.agg('std').reindex(models)\n",
    "df_std.columns.name = 'StdDev'\n",
    "\n",
    "\n",
    "df_edges_agg = df_edges.groupby(level=0)  # Group all metrics from different seeds for each model\n",
    "\n",
    "df_edges_mean = df_edges_agg.agg('mean').reindex(models)\n",
    "df_edges_mean.columns.name = 'Mean'\n",
    "\n",
    "df_edges_std = df_edges_agg.agg('std').reindex(models)\n",
    "df_edges_std.columns.name = 'StdDev'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SHOW DATAFRAMES\n",
    "# display(df)  # Might be quite large, comment out if needed.\n",
    "display(df_mean)\n",
    "# display(df_std)\n",
    "\n",
    "# display(df_edges)  # Might be quite large, comment out if needed.\n",
    "display(df_edges_mean)\n",
    "# display(df_edges_std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LATEX TABLES WITH BEST MODEL\n",
    "metrics = [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1]\n",
    "precision = 4\n",
    "print(TableFormatter.from_df(df_mean, metrics=metrics).to_latex(precision=precision, caption=f'SYNS-Patches {split} performance.'))\n",
    "\n",
    "metrics2 = metrics + [1, -1, -1, -1, -1]\n",
    "print(TableFormatter.from_df(df_edges_mean, metrics=metrics2).to_latex(precision=precision, caption=f'SYNS-Patches {split} edges performance.'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GROUP BY MODEL & CATEGORY\n",
    "df_agg2 = df.groupby(['Cat', 'Model'])  # Group all metrics from different seeds for each model AND CATEGORY\n",
    "\n",
    "df_mean2 = df_agg2.agg('mean')\n",
    "df_mean2.columns.name = 'Mean'\n",
    "\n",
    "df_std2 = df_agg2.agg('std')\n",
    "df_std2.columns.name = 'StdDev'\n",
    "\n",
    "\n",
    "df_edges_agg2 = df_edges.groupby(['Cat-Edges', 'Model'])  # Group all metrics from different seeds for each model AND CATEGORY\n",
    "\n",
    "df_edges_mean2 = df_edges_agg2.agg('mean')\n",
    "df_edges_mean2.columns.name = 'Mean'\n",
    "\n",
    "df_edges_std2 = df_edges_agg2.agg('std')\n",
    "df_edges_std2.columns.name = 'StdDev'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SHOW DATAFRAMES\n",
    "display(df_mean2)\n",
    "# display(df_std2)\n",
    "\n",
    "display(df_edges_mean2)\n",
    "# display(df_edges_std2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LATEX TABLES WITH BEST MODEL\n",
    "# WARNING: This is quite messy when dealing with all the separate categories.\n",
    "metrics = [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1]\n",
    "precision = 4\n",
    "print(TableFormatter.from_df(df_mean2, metrics=metrics).to_latex(precision=precision, caption=f'SYNS-Patches {split} performance over each category.'))\n",
    "\n",
    "\n",
    "metrics2 = metrics + [1, -1, -1, -1, -1]\n",
    "print(TableFormatter.from_df(df_edges_mean2, metrics=metrics2).to_latex(precision=precision, caption=f'SYNS-Patches {split} edge performance over each category.'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}